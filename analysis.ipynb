{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "775b422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import sent_tokenize,WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1c7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e3d62e",
   "metadata": {},
   "source": [
    "### making list of positive and negative words using link given in problem statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f18e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict=pd.read_csv('files/master dictionary/LoughranMcDonald_MasterDictionary_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971acf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words=list(word_dict.Word[word_dict.Positive>0])\n",
    "positive_words=[word.lower() for word in positive_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14906e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words=list(word_dict.Word[word_dict.Negative>0])\n",
    "negative_words=[word.lower() for word in negative_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6381cc9",
   "metadata": {},
   "source": [
    "### making List of stop words using link given in problem statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2635aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=''\n",
    "file_names=['StopWords_Auditor','StopWords_Currencies','StopWords_DatesandNumbers','StopWords_Generic','StopWords_GenericLong','StopWords_Geographic','StopWords_Names']\n",
    "for file_name in file_names:\n",
    "    with open(f'files/stop_words/{file_name}.txt','r') as file:\n",
    "        text+=file.read()\n",
    "stop_words=list(text.replace('|','').split())\n",
    "# stop_words2=stopwords.words('english')\n",
    "# stop_words2\n",
    "# making stop words list from the link given in objective file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c39019",
   "metadata": {},
   "source": [
    "### reading input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f7f03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=pd.read_excel('files/Input.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caeace4",
   "metadata": {},
   "source": [
    "### extracting text files from articles and saving them with their respective id names in articles folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80af960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(url_id,url):\n",
    "    page=requests.get(url, headers={\"User-Agent\": \"XY\"}) \n",
    "    data=page.content\n",
    "    soup=BeautifulSoup(data,'html.parser')\n",
    "    article_title = soup.find('title').text.strip()\n",
    "    article_content=soup.find(\"div\",attrs={'class':\"td-post-content\"}).text.strip()\n",
    "    with open(f\"articles/{url_id}.txt\",'w', encoding=\"utf-8\") as f:\n",
    "        f.write(article_title+'\\n')\n",
    "        f.write(article_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c50b98b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "165    None\n",
       "166    None\n",
       "167    None\n",
       "168    None\n",
       "169    None\n",
       "Length: 170, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.apply(lambda row: extract_text(row['URL_ID'],row['URL']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88d2d81",
   "metadata": {},
   "source": [
    "### function to preprocess text, i.e, break text into sentences and words and then removing stop words from text and lowercasing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88bf5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text:str):\n",
    "    sentences=sent_tokenize(text)\n",
    "    tokens=word_tokenize(text)\n",
    "    lemma=WordNetLemmatizer()\n",
    "    punctuations=['?','!',',','.']\n",
    "    words=[lemma.lemmatize(word.lower()) for word in tokens if word.isalpha() and word not in stop_words and word not in punctuations]\n",
    "    return sentences,tokens,words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482c33b8",
   "metadata": {},
   "source": [
    "### to count positive and negative score of a text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0779b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(words):\n",
    "    pos_score=0\n",
    "    neg_score=0\n",
    "    for word in words:\n",
    "        if word in positive_words:\n",
    "            pos_score+=1\n",
    "        if word in negative_words:\n",
    "            neg_score-=1\n",
    "    neg_score*=-1\n",
    "    return pos_score,neg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b5fc6",
   "metadata": {},
   "source": [
    "### to count complex words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a757bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word:str):\n",
    "    vowels='aeiou'\n",
    "    endings=['es','ed']\n",
    "    syllables=0\n",
    "    for i in word:\n",
    "        if i in vowels:\n",
    "            syllables+=1\n",
    "    for end in endings:\n",
    "        if word.endswith(end):\n",
    "            syllables-=1\n",
    "            break\n",
    "    if word.endswith('le'):\n",
    "        syllables+=1\n",
    "    return syllables\n",
    "def count_complex_words(words):\n",
    "    complex_word_counts=0\n",
    "    total_syllables=0\n",
    "    for word in words:\n",
    "        if count_syllables(word)>2:\n",
    "            complex_word_counts+=1\n",
    "        total_syllables+=1\n",
    "    return complex_word_counts,total_syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988de18f",
   "metadata": {},
   "source": [
    "### to count personal prononuns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fdf86f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pronouns(words):\n",
    "    pronouns=['i','we','us','ours','my','I','We','Us','Ours','My']\n",
    "    pronoun_count=0\n",
    "    for word in words:\n",
    "        if word in pronouns:\n",
    "            pronoun_count+=1\n",
    "    return pronoun_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b936cc",
   "metadata": {},
   "source": [
    "### total number of characters in a text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c146d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_characters(words):\n",
    "    character_count=0\n",
    "    for word in words:\n",
    "        character_count+=len(word)\n",
    "        \n",
    "    return character_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d073d8d",
   "metadata": {},
   "source": [
    "### analyse the text for respective variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbdab2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_text(url_id):\n",
    "    with open(f'articles/{url_id}.txt','r',encoding='utf8') as file:\n",
    "        text=file.read().lower()\n",
    "    sentences,words,cleaned_words=preprocess_text(text)\n",
    "    pos_score,neg_score=score(cleaned_words)\n",
    "    \n",
    "    polarity=round((pos_score-neg_score)/((pos_score+neg_score)+0.000001),6)\n",
    "    \n",
    "    subjectivity=round((pos_score+neg_score)/(len(cleaned_words)+0.000001),6)\n",
    "    \n",
    "    average_sentence_length=round(len(words)/len(sentences))\n",
    "    \n",
    "    complex_word_counts, syllable_count =count_complex_words(words)\n",
    "    \n",
    "    complex_words_percentage=round(complex_word_counts*100/len(words),ndigits=6)\n",
    "    \n",
    "    fog_index=round(.4*(average_sentence_length+complex_words_percentage),ndigits=6)\n",
    "    \n",
    "    clean_word_count=len(cleaned_words)\n",
    "    \n",
    "    syllable_per_word= round(syllable_count/len(words))\n",
    "    \n",
    "    pronoun_count=count_pronouns(words)\n",
    "    \n",
    "    character_count=count_characters(words)\n",
    "    \n",
    "    average_word_length=round(character_count/len(words))\n",
    "    \n",
    "    return pos_score,neg_score,polarity,subjectivity,average_sentence_length,complex_words_percentage,fog_index,average_sentence_length,complex_word_counts,clean_word_count,syllable_per_word,pronoun_count,average_word_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3ab089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making list of all new columns to be added\n",
    "new=['POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE','SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH','PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX','AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT','SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b24b2984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dataframe for storing output\n",
    "output_data=input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a13ed261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe of all new columns to be added for analysed test\n",
    "new_data=pd.DataFrame(list(input_data.apply(lambda row: analyse_text(row['URL_ID']),axis=1)),columns=new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8d8b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining output and new data\n",
    "output_data=output_data.join(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c85e7c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     URL_ID                                                URL  \\\n",
      "0       1.0  https://insights.blackcoffer.com/how-is-login-...   \n",
      "1       2.0  https://insights.blackcoffer.com/how-does-ai-h...   \n",
      "2       3.0  https://insights.blackcoffer.com/ai-and-its-im...   \n",
      "3       4.0  https://insights.blackcoffer.com/how-do-deep-l...   \n",
      "4       5.0  https://insights.blackcoffer.com/how-artificia...   \n",
      "..      ...                                                ...   \n",
      "165   167.0  https://insights.blackcoffer.com/role-big-data...   \n",
      "166   168.0  https://insights.blackcoffer.com/sales-forecas...   \n",
      "167   169.0  https://insights.blackcoffer.com/detect-data-e...   \n",
      "168   170.0  https://insights.blackcoffer.com/data-exfiltra...   \n",
      "169   171.0  https://insights.blackcoffer.com/impacts-of-co...   \n",
      "\n",
      "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
      "0                 2               5       -0.428571            0.019074   \n",
      "1                 7               6        0.076923            0.037791   \n",
      "2                28              20        0.166667            0.049741   \n",
      "3                 5               1        0.666667            0.024896   \n",
      "4                19              16        0.085714            0.057661   \n",
      "..              ...             ...             ...                 ...   \n",
      "165              13              38       -0.490196            0.068919   \n",
      "166              20              12        0.250000            0.057143   \n",
      "167               3              49       -0.884615            0.096475   \n",
      "168               4              10       -0.428571            0.048780   \n",
      "169               1               9       -0.800000            0.026247   \n",
      "\n",
      "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
      "0                     33                    21.760391  21.904156   \n",
      "1                     25                    25.558659  20.223464   \n",
      "2                     26                    26.663381  21.065352   \n",
      "3                     31                    26.626016  23.050406   \n",
      "4                     24                    23.416370  18.966548   \n",
      "..                   ...                          ...        ...   \n",
      "165                   25                    22.706422  19.082569   \n",
      "166                   29                    25.454545  21.781818   \n",
      "167                   21                    26.164875  18.865950   \n",
      "168                   24                    22.222222  18.488889   \n",
      "169                   37                    21.101993  23.240797   \n",
      "\n",
      "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
      "0                                  33                 178         367   \n",
      "1                                  25                 183         344   \n",
      "2                                  26                 541         965   \n",
      "3                                  31                 131         241   \n",
      "4                                  24                 329         607   \n",
      "..                                ...                 ...         ...   \n",
      "165                                25                 396         740   \n",
      "166                                29                 280         560   \n",
      "167                                21                 292         539   \n",
      "168                                24                 150         287   \n",
      "169                                37                 180         381   \n",
      "\n",
      "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
      "0                    1                  4                5  \n",
      "1                    1                  2                5  \n",
      "2                    1                 13                5  \n",
      "3                    1                  1                5  \n",
      "4                    1                 27                5  \n",
      "..                 ...                ...              ...  \n",
      "165                  1                 15                5  \n",
      "166                  1                  0                5  \n",
      "167                  1                  6                5  \n",
      "168                  1                 11                4  \n",
      "169                  1                  1                5  \n",
      "\n",
      "[170 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2c9fa05",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'files/output.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18832/616572947.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'files/output.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2282\u001b[0m             \u001b[0minf_rep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minf_rep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2283\u001b[0m         )\n\u001b[1;32m-> 2284\u001b[1;33m         formatter.write(\n\u001b[0m\u001b[0;32m   2285\u001b[0m             \u001b[0mexcel_writer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2286\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\formats\\excel.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    832\u001b[0m             \u001b[1;31m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[1;31m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m             writer = ExcelWriter(  # type: ignore[abstract]\n\u001b[0m\u001b[0;32m    835\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\excel\\_openpyxl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mengine_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombine_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         super().__init__(\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIOHandles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"copression\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m             self.handles = get_handle(\n\u001b[0m\u001b[0;32m    926\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'files/output.xlsx'"
     ]
    }
   ],
   "source": [
    "output_data.to_excel(f'files/output.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
