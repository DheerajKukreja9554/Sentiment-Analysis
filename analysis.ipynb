{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "775b422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import sent_tokenize,WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1c7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e3d62e",
   "metadata": {},
   "source": [
    "### making list of positive and negative words using link given in problem statement and a list of stop words from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f18e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict=pd.read_csv('files/master dictionary/LoughranMcDonald_MasterDictionary_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "971acf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words=list(word_dict.Word[word_dict.Positive>0])\n",
    "positive_words=[word.lower() for word in positive_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14906e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words=list(word_dict.Word[word_dict.Negative>0])\n",
    "negative_words=[word.lower() for word in negative_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2635aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c39019",
   "metadata": {},
   "source": [
    "### reading input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f7f03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=pd.read_excel('files/Input.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caeace4",
   "metadata": {},
   "source": [
    "### extracting text files from articles and saving them with their respective id names in articles folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80af960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(url_id,url):\n",
    "    page=requests.get(url, headers={\"User-Agent\": \"XY\"}) \n",
    "    data=page.content\n",
    "    soup=BeautifulSoup(data,'html.parser')\n",
    "    article_title = soup.find('title').text.strip()\n",
    "    article_content=soup.find(\"div\",attrs={'class':\"td-post-content\"}).text.strip()\n",
    "    with open(f\"articles/{url_id}.txt\",'w', encoding=\"utf-8\") as f:\n",
    "        f.write(article_title+'\\n')\n",
    "        f.write(article_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c50b98b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "165    None\n",
       "166    None\n",
       "167    None\n",
       "168    None\n",
       "169    None\n",
       "Length: 170, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.apply(lambda row: extract_text(row['URL_ID'],row['URL']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88d2d81",
   "metadata": {},
   "source": [
    "### function to preprocess text, i.e, break text into sentences and words and then removing stop words from text and lowercasing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88bf5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text:str):\n",
    "    sentences=sent_tokenize(text)\n",
    "    tokens=word_tokenize(text)\n",
    "    lemma=WordNetLemmatizer()\n",
    "    punctuations=['?','!',',','.']\n",
    "    words=[lemma.lemmatize(word.lower()) for word in tokens if word.isalpha() and word not in stop_words and word not in punctuations]\n",
    "    return sentences,tokens,words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482c33b8",
   "metadata": {},
   "source": [
    "### to count positive and negative score of a text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0779b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(words):\n",
    "    pos_score=0\n",
    "    neg_score=0\n",
    "    for word in words:\n",
    "        if word in positive_words:\n",
    "            pos_score+=1\n",
    "        if word in negative_words:\n",
    "            neg_score-=1\n",
    "    neg_score*=-1\n",
    "    return pos_score,neg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b5fc6",
   "metadata": {},
   "source": [
    "### to count complex words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a757bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word:str):\n",
    "    vowels='aeiou'\n",
    "    endings=['es','ed']\n",
    "    syllables=0\n",
    "    for i in word:\n",
    "        if i in vowels:\n",
    "            syllables+=1\n",
    "    for end in endings:\n",
    "        if word.endswith(end):\n",
    "            syllables-=1\n",
    "            break\n",
    "    return syllables\n",
    "def count_complex_words(words):\n",
    "    complex_word_counts=0\n",
    "    total_syllables=0\n",
    "    for word in words:\n",
    "        if count_syllables(word)>2:\n",
    "            complex_word_counts+=1\n",
    "        total_syllables+=1\n",
    "    return complex_word_counts,total_syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988de18f",
   "metadata": {},
   "source": [
    "### to count personal prononuns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fdf86f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pronouns(words):\n",
    "    pronouns=['i','we','us','ours','my','I','We','Us','Ours','My']\n",
    "    pronoun_count=0\n",
    "    for word in words:\n",
    "        if word in pronouns:\n",
    "            pronoun_count+=1\n",
    "    return pronoun_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b936cc",
   "metadata": {},
   "source": [
    "### total number of characters in a text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c146d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_characters(words):\n",
    "    character_count=0\n",
    "    for word in words:\n",
    "        character_count+=len(word)\n",
    "        \n",
    "    return character_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d073d8d",
   "metadata": {},
   "source": [
    "### analyse the text for respective variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbdab2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_text(url_id):\n",
    "    with open(f'articles/{url_id}.txt','r',encoding='utf8') as file:\n",
    "        text=file.read().lower()\n",
    "    sentences,words,cleaned_words=preprocess_text(text)\n",
    "    pos_score,neg_score=score(cleaned_words)\n",
    "    \n",
    "    polarity=round((pos_score-neg_score)/((pos_score+neg_score)+0.000001),6)\n",
    "    \n",
    "    subjectivity=round((pos_score+neg_score)/(len(cleaned_words)+0.000001),6)\n",
    "    \n",
    "    average_sentence_length=round(len(words)/len(sentences))\n",
    "    \n",
    "    complex_word_counts, syllable_count =count_complex_words(words)\n",
    "    \n",
    "    complex_words_percentage=round(complex_word_counts*100/len(words),ndigits=6)\n",
    "    \n",
    "    fog_index=round(.4*(average_sentence_length+complex_words_percentage),ndigits=6)\n",
    "    \n",
    "    clean_word_count=len(cleaned_words)\n",
    "    \n",
    "    syllable_per_word= round(syllable_count/len(words))\n",
    "    \n",
    "    pronoun_count=count_pronouns(words)\n",
    "    \n",
    "    character_count=count_characters(words)\n",
    "    \n",
    "    average_word_length=round(character_count/len(words))\n",
    "    \n",
    "    return pos_score,neg_score,polarity,subjectivity,average_sentence_length,complex_words_percentage,fog_index,average_sentence_length,complex_word_counts,clean_word_count,syllable_per_word,pronoun_count,average_word_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3ab089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making list of all new columns to be added\n",
    "new=['POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE','SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH','PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX','AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT','SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b24b2984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dataframe for storing output\n",
    "output_data=input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a13ed261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe of all new columns to be added for analysed test\n",
    "new_data=pd.DataFrame(list(input_data.apply(lambda row: analyse_text(row['URL_ID']),axis=1)),columns=new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8d8b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining output and new data\n",
    "output_data=output_data.join(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c85e7c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.021378</td>\n",
       "      <td>33</td>\n",
       "      <td>21.638142</td>\n",
       "      <td>21.855257</td>\n",
       "      <td>33</td>\n",
       "      <td>177</td>\n",
       "      <td>421</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>25</td>\n",
       "      <td>24.860335</td>\n",
       "      <td>19.944134</td>\n",
       "      <td>25</td>\n",
       "      <td>178</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.049952</td>\n",
       "      <td>26</td>\n",
       "      <td>26.269098</td>\n",
       "      <td>20.907639</td>\n",
       "      <td>26</td>\n",
       "      <td>533</td>\n",
       "      <td>1041</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.026718</td>\n",
       "      <td>31</td>\n",
       "      <td>26.626016</td>\n",
       "      <td>23.050406</td>\n",
       "      <td>31</td>\n",
       "      <td>131</td>\n",
       "      <td>262</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.053812</td>\n",
       "      <td>24</td>\n",
       "      <td>23.131673</td>\n",
       "      <td>18.852669</td>\n",
       "      <td>24</td>\n",
       "      <td>325</td>\n",
       "      <td>669</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>167.0</td>\n",
       "      <td>https://insights.blackcoffer.com/role-big-data...</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.433962</td>\n",
       "      <td>0.062871</td>\n",
       "      <td>25</td>\n",
       "      <td>21.846330</td>\n",
       "      <td>18.738532</td>\n",
       "      <td>25</td>\n",
       "      <td>381</td>\n",
       "      <td>843</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>168.0</td>\n",
       "      <td>https://insights.blackcoffer.com/sales-forecas...</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.056410</td>\n",
       "      <td>29</td>\n",
       "      <td>25.272727</td>\n",
       "      <td>21.709091</td>\n",
       "      <td>29</td>\n",
       "      <td>278</td>\n",
       "      <td>585</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>169.0</td>\n",
       "      <td>https://insights.blackcoffer.com/detect-data-e...</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.884615</td>\n",
       "      <td>0.093190</td>\n",
       "      <td>21</td>\n",
       "      <td>25.448029</td>\n",
       "      <td>18.579212</td>\n",
       "      <td>21</td>\n",
       "      <td>284</td>\n",
       "      <td>558</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>170.0</td>\n",
       "      <td>https://insights.blackcoffer.com/data-exfiltra...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>0.044164</td>\n",
       "      <td>24</td>\n",
       "      <td>21.777778</td>\n",
       "      <td>18.311111</td>\n",
       "      <td>24</td>\n",
       "      <td>147</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>171.0</td>\n",
       "      <td>https://insights.blackcoffer.com/impacts-of-co...</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.036058</td>\n",
       "      <td>37</td>\n",
       "      <td>20.281360</td>\n",
       "      <td>22.912544</td>\n",
       "      <td>37</td>\n",
       "      <td>173</td>\n",
       "      <td>416</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0       1.0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1       2.0  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2       3.0  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3       4.0  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4       5.0  https://insights.blackcoffer.com/how-artificia...   \n",
       "..      ...                                                ...   \n",
       "165   167.0  https://insights.blackcoffer.com/role-big-data...   \n",
       "166   168.0  https://insights.blackcoffer.com/sales-forecas...   \n",
       "167   169.0  https://insights.blackcoffer.com/detect-data-e...   \n",
       "168   170.0  https://insights.blackcoffer.com/data-exfiltra...   \n",
       "169   171.0  https://insights.blackcoffer.com/impacts-of-co...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0                 4               5       -0.111111            0.021378   \n",
       "1                 8               6        0.142857            0.036842   \n",
       "2                32              20        0.230769            0.049952   \n",
       "3                 6               1        0.714286            0.026718   \n",
       "4                20              16        0.111111            0.053812   \n",
       "..              ...             ...             ...                 ...   \n",
       "165              15              38       -0.433962            0.062871   \n",
       "166              21              12        0.272727            0.056410   \n",
       "167               3              49       -0.884615            0.093190   \n",
       "168               4              10       -0.428571            0.044164   \n",
       "169               6               9       -0.200000            0.036058   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                     33                    21.638142  21.855257   \n",
       "1                     25                    24.860335  19.944134   \n",
       "2                     26                    26.269098  20.907639   \n",
       "3                     31                    26.626016  23.050406   \n",
       "4                     24                    23.131673  18.852669   \n",
       "..                   ...                          ...        ...   \n",
       "165                   25                    21.846330  18.738532   \n",
       "166                   29                    25.272727  21.709091   \n",
       "167                   21                    25.448029  18.579212   \n",
       "168                   24                    21.777778  18.311111   \n",
       "169                   37                    20.281360  22.912544   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                  33                 177         421   \n",
       "1                                  25                 178         380   \n",
       "2                                  26                 533        1041   \n",
       "3                                  31                 131         262   \n",
       "4                                  24                 325         669   \n",
       "..                                ...                 ...         ...   \n",
       "165                                25                 381         843   \n",
       "166                                29                 278         585   \n",
       "167                                21                 284         558   \n",
       "168                                24                 147         317   \n",
       "169                                37                 173         416   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                    1                  4                5  \n",
       "1                    1                  2                5  \n",
       "2                    1                 13                5  \n",
       "3                    1                  1                5  \n",
       "4                    1                 27                5  \n",
       "..                 ...                ...              ...  \n",
       "165                  1                 15                5  \n",
       "166                  1                  0                5  \n",
       "167                  1                  6                5  \n",
       "168                  1                 11                4  \n",
       "169                  1                  1                5  \n",
       "\n",
       "[170 rows x 15 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d45cf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>170.000000</td>\n",
       "      <td>170.00000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>170.0</td>\n",
       "      <td>170.00000</td>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>86.247059</td>\n",
       "      <td>14.80000</td>\n",
       "      <td>21.882353</td>\n",
       "      <td>-0.078236</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>26.776471</td>\n",
       "      <td>22.513666</td>\n",
       "      <td>19.716055</td>\n",
       "      <td>26.776471</td>\n",
       "      <td>284.664706</td>\n",
       "      <td>620.494118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.40000</td>\n",
       "      <td>4.758824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>49.547994</td>\n",
       "      <td>9.71158</td>\n",
       "      <td>18.383754</td>\n",
       "      <td>0.492179</td>\n",
       "      <td>0.022251</td>\n",
       "      <td>14.262440</td>\n",
       "      <td>3.636588</td>\n",
       "      <td>5.865223</td>\n",
       "      <td>14.262440</td>\n",
       "      <td>127.281914</td>\n",
       "      <td>275.570548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.13961</td>\n",
       "      <td>0.429061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.663067</td>\n",
       "      <td>12.065589</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>43.500000</td>\n",
       "      <td>7.25000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-0.441967</td>\n",
       "      <td>0.041648</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>20.175687</td>\n",
       "      <td>17.532314</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>86.500000</td>\n",
       "      <td>13.50000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.055795</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>22.191959</td>\n",
       "      <td>19.266744</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>597.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>128.750000</td>\n",
       "      <td>20.75000</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.070979</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>24.965084</td>\n",
       "      <td>21.144596</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>375.750000</td>\n",
       "      <td>817.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>171.000000</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.138996</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>32.125604</td>\n",
       "      <td>84.874043</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>658.000000</td>\n",
       "      <td>1927.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           URL_ID  POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  \\\n",
       "count  170.000000       170.00000      170.000000      170.000000   \n",
       "mean    86.247059        14.80000       21.882353       -0.078236   \n",
       "std     49.547994         9.71158       18.383754        0.492179   \n",
       "min      1.000000         0.00000        0.000000       -1.000000   \n",
       "25%     43.500000         7.25000        9.000000       -0.441967   \n",
       "50%     86.500000        13.50000       18.000000       -0.142857   \n",
       "75%    128.750000        20.75000       32.750000        0.333333   \n",
       "max    171.000000        47.00000      121.000000        1.000000   \n",
       "\n",
       "       SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  \\\n",
       "count          170.000000           170.000000                   170.000000   \n",
       "mean             0.057684            26.776471                    22.513666   \n",
       "std              0.022251            14.262440                     3.636588   \n",
       "min              0.009901            15.000000                    11.663067   \n",
       "25%              0.041648            22.000000                    20.175687   \n",
       "50%              0.055795            25.000000                    22.191959   \n",
       "75%              0.070979            28.000000                    24.965084   \n",
       "max              0.138996           191.000000                    32.125604   \n",
       "\n",
       "        FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  \\\n",
       "count  170.000000                        170.000000          170.000000   \n",
       "mean    19.716055                         26.776471          284.664706   \n",
       "std      5.865223                         14.262440          127.281914   \n",
       "min     12.065589                         15.000000           35.000000   \n",
       "25%     17.532314                         22.000000          184.000000   \n",
       "50%     19.266744                         25.000000          277.000000   \n",
       "75%     21.144596                         28.000000          375.750000   \n",
       "max     84.874043                        191.000000          658.000000   \n",
       "\n",
       "        WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "count   170.000000              170.0          170.00000       170.000000  \n",
       "mean    620.494118                1.0            6.40000         4.758824  \n",
       "std     275.570548                0.0            8.13961         0.429061  \n",
       "min      88.000000                1.0            0.00000         4.000000  \n",
       "25%     413.000000                1.0            1.00000         5.000000  \n",
       "50%     597.000000                1.0            4.00000         5.000000  \n",
       "75%     817.000000                1.0            8.00000         5.000000  \n",
       "max    1927.000000                1.0           44.00000         5.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a4b620d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 170 entries, 0 to 169\n",
      "Data columns (total 15 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   URL_ID                            170 non-null    float64\n",
      " 1   URL                               170 non-null    object \n",
      " 2   POSITIVE SCORE                    170 non-null    int64  \n",
      " 3   NEGATIVE SCORE                    170 non-null    int64  \n",
      " 4   POLARITY SCORE                    170 non-null    float64\n",
      " 5   SUBJECTIVITY SCORE                170 non-null    float64\n",
      " 6   AVG SENTENCE LENGTH               170 non-null    int64  \n",
      " 7   PERCENTAGE OF COMPLEX WORDS       170 non-null    float64\n",
      " 8   FOG INDEX                         170 non-null    float64\n",
      " 9   AVG NUMBER OF WORDS PER SENTENCE  170 non-null    int64  \n",
      " 10  COMPLEX WORD COUNT                170 non-null    int64  \n",
      " 11  WORD COUNT                        170 non-null    int64  \n",
      " 12  SYLLABLE PER WORD                 170 non-null    int64  \n",
      " 13  PERSONAL PRONOUNS                 170 non-null    int64  \n",
      " 14  AVG WORD LENGTH                   170 non-null    int64  \n",
      "dtypes: float64(5), int64(9), object(1)\n",
      "memory usage: 20.0+ KB\n"
     ]
    }
   ],
   "source": [
    "output_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3e83a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL_ID                                                                           97.0\n",
       "URL                                 https://insights.blackcoffer.com/how-will-covi...\n",
       "POSITIVE SCORE                                                                      7\n",
       "NEGATIVE SCORE                                                                     18\n",
       "POLARITY SCORE                                                                  -0.44\n",
       "SUBJECTIVITY SCORE                                                           0.056818\n",
       "AVG SENTENCE LENGTH                                                                77\n",
       "PERCENTAGE OF COMPLEX WORDS                                                 11.663067\n",
       "FOG INDEX                                                                   35.465227\n",
       "AVG NUMBER OF WORDS PER SENTENCE                                                   77\n",
       "COMPLEX WORD COUNT                                                                108\n",
       "WORD COUNT                                                                        440\n",
       "SYLLABLE PER WORD                                                                   1\n",
       "PERSONAL PRONOUNS                                                                  44\n",
       "AVG WORD LENGTH                                                                     4\n",
       "Name: 95, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data.loc[95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2c9fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data.to_excel(f'files/output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63d26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
